{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tfds.load('multi_news', split='train', with_info=True)\n",
    "\n",
    "#use index to get specific document\n",
    "index = 20\n",
    "count = 0\n",
    "with tf.Graph().as_default():\n",
    "    numpy_imgs = next(iter(ds))\n",
    "    # numpy_imgs = tfds.as_numpy(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "document = []\n",
    "summary = []\n",
    "for x in numpy_imgs:\n",
    "    count += 1\n",
    "    if count == index:\n",
    "        # tf.print(x[\"document\"])\n",
    "        # print(\"\\n\")\n",
    "        # print(\"\\n\")\n",
    "        # print(\"SUMMARY\")\n",
    "        # tf.print(x[\"summary\"])\n",
    "\n",
    "        document = x[\"document\"]\n",
    "        summary = x[\"summary\"]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = bytes(document.numpy())\n",
    "document = [document.decode(\"utf-8\")]\n",
    "\n",
    "summary = bytes(summary.numpy())\n",
    "summary = [summary.decode(\"utf-8\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['–', 'umberto', 'eco', 'started', 'working', 'on', 'a', 'novel', 'that', 'set', 'the', \"world's\", 'imagination', 'on', 'fire', '\"prodded', 'by', 'a', 'seminal', 'idea:', 'i', 'felt', 'like', 'poisoning', 'a', 'monk.\"', 'the', 'italian', 'author', 'and', 'academic', 'who', 'intrigued,', 'puzzled,', 'and', 'delighted', 'readers', 'worldwide', 'with', 'his', 'best-selling', 'historical', 'novel', 'the', 'name', 'of', 'the', 'rose', 'died', 'at', 'home', 'in', 'milan', 'on', 'friday', 'evening', 'after', 'a', 'battle', 'with', 'cancer,', 'a', 'family', 'member', 'tells', 'the', 'ap.', 'he', 'was', '84.', 'author', 'of', 'a', 'wide', 'range', 'of', 'books,', 'eco', 'was', 'fascinated', 'with', 'the', 'obscure', 'and', 'the', 'mundane,', 'and', 'his', 'books', 'were', 'both', 'engaging', 'narratives', 'and', 'philosophical', 'and', 'intellectual', 'exercises.', 'the', 'name', 'of', 'the', 'rose', 'transformed', 'him', 'from', 'an', 'academic', 'to', 'international', 'celebrity,', 'especially', 'after', 'the', 'medieval', 'thriller', 'set', 'in', 'a', 'monastery', 'was', 'made', 'into', 'a', 'film', 'starring', 'sean', 'connery', 'in', '1986.', 'his', 'second', 'novel,', \"1988's\", \"foucault's\", 'pendulum,', 'a', 'byzantine', 'tale', 'of', 'plotting', 'publishers', 'and', 'secret', 'sects,', 'was', 'successful,', 'too—though', 'it', 'was', 'so', 'complicated', 'that', 'an', 'annotated', 'guide', 'accompanied', 'it', 'to', 'help', 'the', 'reader', 'follow', 'the', 'plot.', 'eco—whose', 'most', 'recent', 'novel,', 'numero', 'zero,', 'came', 'out', 'last', 'year', 'and', 'recalled', 'a', \"'90s\", 'political', 'scandal', 'that', 'helped', 'lead', 'to', 'the', 'rise', 'of', 'silvio', 'berlusconi—shrugged', 'off', 'critics', 'who', 'found', 'him', '\"too', 'erudite', 'and', 'philosophical,', 'too', 'difficult,\"', 'telling', 'the', 'guardian', 'in', 'a', '2011', 'interview', 'that', 'he', 'wrote', '\"for', 'masochists.\"', '\"it\\'s', 'only', 'publishers', 'and', 'some', 'journalists', 'who', 'believe', 'that', 'people', 'want', 'simple', 'things,\"', 'he', 'said.', '\"people', 'are', 'tired', 'of', 'simple', 'things.', 'they', 'want', 'to', 'be', 'challenged.\"', '(the', 'death', 'of', 'harper', 'lee', 'was', 'also', 'announced', 'on', 'friday.)']\n",
      "[494, 12, 13, 53, 54, 60, 4, 55, 56, 57, 22, 58, 59, 60, 61, 62, 63, 4, 64, 65, 66, 67, 68, 69, 4, 70, 22, 10, 106, 75, 146, 72, 73, 1288, 75, 76, 77, 78, 79, 80, 81, 82, 55, 22, 38, 39, 22, 484, 41, 21, 85, 3, 50, 60, 86, 87, 88, 4, 89, 79, 90, 4, 91, 92, 1289, 22, 1290, 16, 98, 1291, 106, 39, 4, 107, 108, 39, 109, 13, 98, 110, 79, 22, 111, 75, 22, 112, 75, 80, 113, 114, 115, 116, 117, 75, 118, 75, 119, 120, 22, 38, 39, 22, 484, 142, 143, 144, 145, 146, 46, 35, 147, 148, 88, 22, 149, 150, 57, 3, 4, 151, 98, 152, 153, 4, 154, 155, 156, 157, 3, 158, 80, 173, 174, 1292, 685, 686, 4, 178, 179, 39, 180, 181, 75, 182, 1293, 98, 186, 1294, 189, 98, 190, 191, 56, 145, 192, 193, 194, 189, 46, 195, 22, 196, 197, 22, 198, 1295, 396, 369, 174, 1296, 1297, 399, 400, 401, 358, 75, 402, 4, 1298, 403, 404, 56, 406, 407, 46, 22, 1299, 39, 391, 1300, 452, 453, 72, 454, 143, 455, 456, 75, 457, 187, 458, 1033, 22, 410, 3, 4, 8, 409, 56, 16, 260, 460, 461, 462, 463, 181, 75, 464, 465, 72, 466, 56, 467, 468, 469, 470, 16, 433, 471, 216, 472, 39, 469, 473, 270, 468, 46, 95, 474, 1301, 97, 39, 1302, 1303, 98, 99, 1304, 60, 1305]\n"
     ]
    }
   ],
   "source": [
    "#create vocab\n",
    "d_tokens = document[0].lower().split()\n",
    "s_tokens = summary[0].lower().split()\n",
    "tokens = d_tokens + s_tokens\n",
    "vocab, index = {}, 1\n",
    "vocab[\"<pad>\"] = 0\n",
    "for token in tokens:\n",
    "    if token not in vocab:\n",
    "        vocab[token] = index\n",
    "        index = index + 1\n",
    "\n",
    "inverse_vocab = {index: token for token, index in vocab.items()}\n",
    "example = [vocab[word] for word in s_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.27107972 -0.01055073 -0.05728397  0.06853679 -0.08438271  0.22396211\n",
      "  -0.00247001 -0.09797598 -0.06092518  0.01678422  0.0183306  -0.02683547\n",
      "   0.01987647  0.02205245  0.0380337   0.02345292 -0.0535214  -0.02916854\n",
      "  -0.13816142  0.255649    0.00548296  0.08994407  0.09702856 -0.01617393\n",
      "   0.15273312  0.03449007  0.05599031  0.01964826 -0.01901525  0.11601479\n",
      "   0.06575833 -0.03560898 -0.02412845 -0.00716866 -0.08950593 -0.01021391\n",
      "   0.07431487 -0.10462939 -0.03951982  0.00272066 -0.01468687 -0.01350653\n",
      "  -0.04825642  0.03088917 -0.0448269  -0.01743765  0.1034883   0.04149228\n",
      "  -0.03979184  0.03878277  0.15273733 -0.09228262 -0.01723959  0.01830614\n",
      "  -0.02075483  0.0800882  -0.08071491 -0.15573218  0.13893387  0.06140287\n",
      "  -0.05639812 -0.05526257 -0.02765993 -0.175832    0.01034007 -0.19550695\n",
      "   0.06209265 -0.03193678  0.08837268 -0.05629309  0.09268684  0.05395978\n",
      "  -0.01900527 -0.17626993 -0.03103094 -0.12204378 -0.00157093 -0.07853678\n",
      "  -0.05892268  0.11311311  0.00749602  0.17720635  0.00705703 -0.02477936\n",
      "   0.01754808 -0.10708189  0.01354044 -0.02276768  0.18480518  0.23878463\n",
      "   0.02690842  0.17486377  0.15445334  0.04336881  0.10030321  0.03473791\n",
      "   0.13695279 -0.01135186  0.10339782 -0.04216714  0.15414187  0.00816383\n",
      "  -0.09016436  0.05382214 -0.00468258 -0.03378959 -0.06590898  0.03239544\n",
      "  -0.05416648  0.00577813  0.00359992 -0.1197789   0.03960301 -0.09633037\n",
      "  -0.03632317  0.04465347  0.08645485  0.03435422 -0.01637179 -0.02096656\n",
      "   0.10808575 -0.09299634  0.06655572 -0.04052928 -0.08087688 -0.1576648\n",
      "   0.03123586  0.02210312]\n",
      " [ 0.24816465 -0.06619297 -0.07488655 -0.0434025  -0.08399508  0.11924921\n",
      "  -0.07240637 -0.06224827 -0.0619347  -0.10450241  0.09173684 -0.0157325\n",
      "  -0.00665783 -0.03739307  0.04591279 -0.10748252 -0.03960943 -0.01221685\n",
      "  -0.15646328  0.28827062 -0.05034578  0.06034692 -0.06292915 -0.12956862\n",
      "   0.06275239  0.05485379  0.10006846 -0.05434096 -0.07562272  0.02795899\n",
      "   0.02877025 -0.03873997  0.08480944  0.10531907 -0.07284793 -0.00243958\n",
      "  -0.06184474 -0.11018215 -0.05470686  0.02247239 -0.02980752 -0.02966652\n",
      "  -0.02023029 -0.05196458  0.08784661 -0.01775759 -0.03682138 -0.04811873\n",
      "  -0.09006107  0.10117017  0.10831158 -0.01668864  0.07171492  0.07705168\n",
      "   0.02387583 -0.0261501  -0.04829222  0.04328855  0.02772755 -0.05743307\n",
      "  -0.01383987 -0.0569593  -0.06737578 -0.09332056  0.02847968 -0.10889357\n",
      "  -0.03210738 -0.05884559  0.05467662 -0.08974586 -0.07166561  0.03896518\n",
      "   0.10429208 -0.06946753  0.00462049 -0.1334935  -0.15643585  0.01501083\n",
      "  -0.10304678  0.13439935 -0.00136194  0.04372552  0.00499131  0.02251436\n",
      "  -0.07825701  0.01211459 -0.10891134 -0.09566517  0.19746777  0.20468362\n",
      "  -0.01937577  0.08558907 -0.02050492 -0.07046179  0.07654233  0.04140148\n",
      "   0.221628   -0.12482118  0.11911826 -0.1242468   0.12674199 -0.00684475\n",
      "  -0.0930409   0.08155327  0.00574383 -0.0432922  -0.07563888  0.01789355\n",
      "  -0.01771837 -0.08992799  0.00103209 -0.08330975  0.14422818  0.09882832\n",
      "  -0.02616246  0.02361001  0.13217404 -0.02489127 -0.02765685 -0.07560521\n",
      "   0.01649955 -0.09440068 -0.06909272 -0.08880886 -0.06736004 -0.13825142\n",
      "   0.17052694  0.12467341]], shape=(2, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/nnlm-en-dim128/2\")\n",
    "embeddings = embed([\"cat is on the mat\", \"dog is in the fog\"])\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: C:\\Users\\Brad\\AppData\\Local\\Temp\\tfhub_modules\\602d30248ff7929470db09f7385fc895e9ceb4c0\\{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7949aff29705>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#lean word2vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpreprocess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mbert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://tfhub.dev/google/experts/bert/wiki_books/2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_hub\\module_v2.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m    104\u001b[0m         module_path, tags=tags, options=options)\n\u001b[0;32m    105\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m   \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    862\u001b[0m   \"\"\"\n\u001b[0;32m    863\u001b[0m   \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementReadApi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LOAD_V2_LABEL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 864\u001b[1;33m   \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"root\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    865\u001b[0m   \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementRead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload_internal\u001b[1;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[0;32m    876\u001b[0m     \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m   saved_model_proto, debug_info = (\n\u001b[1;32m--> 878\u001b[1;33m       loader_impl.parse_saved_model_with_debug_info(export_dir))\n\u001b[0m\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m   if (len(saved_model_proto.meta_graphs) == 1 and\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model_with_debug_info\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mparsed\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mMissing\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mfine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m   \"\"\"\n\u001b[1;32m---> 60\u001b[1;33m   \u001b[0msaved_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m   debug_info_path = os.path.join(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    116\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     raise IOError(\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: C:\\Users\\Brad\\AppData\\Local\\Temp\\tfhub_modules\\602d30248ff7929470db09f7385fc895e9ceb4c0\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "# stuff to do\n",
    "# get vocabulary\n",
    "# display output in a visual way\n",
    "#lean word2vec\n",
    "\n",
    "preprocess = hub.load('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
    "bert = hub.load('https://tfhub.dev/google/experts/bert/wiki_books/2')\n",
    "\n",
    "sentences = [\n",
    "  \"Here We Go Then, You And I is a 1999 album by Norwegian pop artist Morten Abel. It was Abel's second CD as a solo artist.\",\n",
    "  \"The album went straight to number one on the Norwegian album chart, and sold to double platinum.\",\n",
    "  \"Among the singles released from the album were the songs \\\"Be My Lover\\\" and \\\"Hard To Stay Awake\\\".\",\n",
    "  \"Riccardo Zegna is an Italian jazz musician.\",\n",
    "  \"Rajko Maksimović is a composer, writer, and music pedagogue.\",\n",
    "  \"One of the most significant Serbian composers of our time, Maksimović has been and remains active in creating works for different ensembles.\",\n",
    "  \"Ceylon spinach is a common name for several plants and may refer to: Basella alba Talinum fruticosum\",\n",
    "  \"A solar eclipse occurs when the Moon passes between Earth and the Sun, thereby totally or partly obscuring the image of the Sun for a viewer on Earth.\",\n",
    "  \"A partial solar eclipse occurs in the polar regions of the Earth when the center of the Moon's shadow misses the Earth.\",\n",
    "]\n",
    "\n",
    "wordArray = []\n",
    "\n",
    "for i in sentences:\n",
    "  words = i.split()\n",
    "  for w in words:\n",
    "    w = w.replace(\",\", \"\")\n",
    "    w = w.replace(\".\", \"\")\n",
    "    wordArray.append(w)\n",
    "\n",
    "print(\"word array\")\n",
    "print(wordArray)\n",
    "\n",
    "bert_inputs = preprocess(sentences)\n",
    "bert_outputs = bert(bert_inputs)\n",
    "pooled_output = bert_outputs['pooled_output']\n",
    "sequence_output = bert_outputs['sequence_output']\n",
    "\n",
    "print('\\nPooled output:')\n",
    "print(pooled_output)\n",
    "print('\\nSequence output:')\n",
    "print(sequence_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similarity(features, labels):\n",
    "  \"\"\"Plot a similarity matrix of the embeddings.\"\"\"\n",
    "  cos_sim = pairwise.cosine_similarity(features)\n",
    "  sns.set(font_scale=1.2)\n",
    "  cbar_kws=dict(use_gridspec=False, location=\"left\")\n",
    "  g = sns.heatmap(\n",
    "      cos_sim, xticklabels=labels, yticklabels=labels,\n",
    "      vmin=0, vmax=1, cmap=\"Blues\", cbar_kws=cbar_kws)\n",
    "  g.tick_params(labelright=True, labelleft=False)\n",
    "  g.set_yticklabels(labels, rotation=0)\n",
    "  g.set_title(\"Semantic Textual Similarity\")\n",
    "\n",
    "plot_similarity(bert_outputs[\"pooled_output\"], wordArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c931ba401747e1100110d99c7b2e1195adf3961a7e00160e720e39c4d164b397"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
